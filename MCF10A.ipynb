{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallmark = pd.read_excel('/ihome/hosmanbeyoglu/kor11/tools/CITRUS/FW__MCF10A_wild_type_and_PIK3CA_H1047R_knock-in_cell_lines/Supplementary Table S4.xlsx', \n",
    "    sheet_name='MCF10A_hallmark_PI3K_Inhibition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Data, get_ppi_edge_list\n",
    "\n",
    "data_csv = Data(\n",
    "    fGEP_SGA = 'data/CITRUS_GEP_SGAseparated.csv',\n",
    "    fgene_tf_SGA = 'data/CITRUS_gene_tf_SGAseparated.csv',\n",
    "    fcancerType_SGA = 'data/CITRUS_canType_SGAseparated.csv',\n",
    "    fSGA_SGA = 'data/CITRUS_SGA_SGAseparated.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;21m(utils.py : 457) -    DEBUG | Loaded 352251 edges from the SIGNOR and SNAP Networks\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ppi = pd.DataFrame(get_ppi_edge_list(sparse=False)[:, :2], columns=['A', 'B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_ppi = ppi[ppi.A.isin(data_csv.tf) | ppi.B.isin(data_csv.tf)]\n",
    "# tfs = pd.DataFrame(data_csv.tf)\n",
    "# tfs.columns = ['tf']\n",
    "# tfs['interacts_with'] = tfs.tf.apply(lambda x: set(tf_ppi[(tf_ppi==x).any(axis=1)].values.reshape(-1)))\n",
    "# tfs = dict(zip(tfs['tf'], tfs['interacts_with']))\n",
    "# def does_interact(tf, geneset):\n",
    "#     if tf in geneset or len(tfs.get(tf, set()).intersection(geneset)) > 0:\n",
    "#         return True            \n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pbar = tqdm(total=len(hallmark.values))\n",
    "# hallmark_mask = np.zeros((hallmark.shape[0], len(data_csv.tf)), dtype=int)\n",
    "\n",
    "# for idx, (pathway, genes) in enumerate(hallmark.values):\n",
    "#     for idy, tf in enumerate(data_csv.tf):\n",
    "#         pbar.set_description(f'{pathway[9:]} | ({idy}/{len(data_csv.tf)}) - {tf}')\n",
    "#         if does_interact(tf, genes.split('/')):\n",
    "#             hallmark_mask[idx, idy] = 1\n",
    "    \n",
    "#     pbar.update(1)\n",
    "# pbar.close()\n",
    "\n",
    "# np.save('hallmark_mask.npy', hallmark_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallmark_mask = np.load('hallmark_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "from utils import bool_ext, load_dataset, split_dataset, evaluate, checkCorrelations\n",
    "from models import CITRUS\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import metrics\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open('args.yaml', 'r') as f:\n",
    "    args_dict = yaml.safe_load(f)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if device == 'cuda':\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "else:\n",
    "    device_name = 'cpu'\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = argparse.Namespace(**args_dict)\n",
    "args.tf_gene = np.load('tf_gene.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ae56f581b3445685c219c0f370b2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, dataset_test = load_dataset(\n",
    "    input_dir=args.input_dir,\n",
    "    mask01=args.mask01,\n",
    "    dataset_name=args.dataset_name,\n",
    "    gep_normalization=args.gep_normalization,\n",
    ")\n",
    "\n",
    "train_set, test_set = split_dataset(dataset, ratio=0.66)\n",
    "\n",
    "daata = pickle.load( open(\"/ihome/hosmanbeyoglu/kor11/tools/CITRUS/data/dataset_CITRUS.pkl\", \"rb\") )\n",
    "cancers = daata['idx2can']\n",
    "\n",
    "\n",
    "models = []\n",
    "for m in tqdm(list(Path('./output').iterdir())):\n",
    "    model = CITRUS(args) \n",
    "    model.build(device=device)\n",
    "    model.to(device);\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(m, map_location=torch.device('cpu')))\n",
    "    except:\n",
    "        checkpoint = torch.load(m, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    preds, tf, hid_tmr, tf, _, _  = model.forward(\n",
    "                torch.tensor(test_set['sga']), \n",
    "                torch.from_numpy(test_set['can'])\n",
    "            )\n",
    "        \n",
    "    genes_ = test_set['gep'].shape[1]\n",
    "    test_df = pd.DataFrame(np.concatenate([test_set['gep'], \n",
    "                                            test_set['can'], \n",
    "                                            preds.detach().cpu().numpy()], axis=1))\n",
    "\n",
    "    test_cancers = {}\n",
    "    for ix, canc in cancers.items():\n",
    "        test_cancers[canc] =  {}\n",
    "        test_cancers[canc]['test'] = test_df[test_df[genes_]==ix+1].values[:, :genes_]    \n",
    "        test_cancers[canc]['pred'] = test_df[test_df[genes_]==ix+1].values[:, genes_+1:] \n",
    "        \n",
    "    o = ['BLCA', 'BRCA', 'CESC', 'COAD', \n",
    "        'ESCA', 'GBM', 'HNSC', 'KIRC', \n",
    "        'KIRP', 'LIHC', 'LUAD', 'LUSC', \n",
    "        'PCPG', 'PRAD', 'STAD', 'THCA', \n",
    "        'UCEC']\n",
    "\n",
    "    _corrs = []\n",
    "    _mses = []\n",
    "    for canc in o:\n",
    "            corr = checkCorrelations(test_cancers[canc]['test'], test_cancers[canc]['pred'], return_value=True)\n",
    "            mse = metrics.mean_squared_error(test_cancers[canc]['test'], test_cancers[canc]['pred'])\n",
    "            \n",
    "            _corrs.append(corr)\n",
    "            _mses.append(mse)\n",
    "            \n",
    "    model.performance = np.column_stack([_corrs, _mses])\n",
    "    model.cancers = o\n",
    "    \n",
    "    if model.my_pvals() > 0.3 and model.performance[:, 0].mean() > 0.8:\n",
    "        models.append(model)\n",
    "\n",
    "    # model.save_model(os.path.join(args.output_dir, m.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.88500166, 0.21723817],\n",
       "        [0.9088142 , 0.17230479],\n",
       "        [0.89025159, 0.20829177],\n",
       "        [0.9180949 , 0.16084542],\n",
       "        [0.89496428, 0.20140234],\n",
       "        [0.87769788, 0.22985205],\n",
       "        [0.90883987, 0.17560549],\n",
       "        [0.91671222, 0.16264574],\n",
       "        [0.89982433, 0.1916358 ],\n",
       "        [0.89209282, 0.20712904],\n",
       "        [0.90350115, 0.1839169 ],\n",
       "        [0.90486963, 0.18138063],\n",
       "        [0.85772384, 0.26870851],\n",
       "        [0.93815202, 0.12384202],\n",
       "        [0.90208831, 0.19048638],\n",
       "        [0.91570582, 0.16329574],\n",
       "        [0.88213537, 0.22326225]]),\n",
       " array([[0.88345781, 0.22032512],\n",
       "        [0.90890721, 0.17235389],\n",
       "        [0.88912574, 0.21072511],\n",
       "        [0.9179067 , 0.16177532],\n",
       "        [0.896419  , 0.19971671],\n",
       "        [0.87048997, 0.24112187],\n",
       "        [0.90742009, 0.17860153],\n",
       "        [0.91449219, 0.16575637],\n",
       "        [0.89877861, 0.19478209],\n",
       "        [0.89263518, 0.20520056],\n",
       "        [0.90233168, 0.1854326 ],\n",
       "        [0.90652395, 0.1783457 ],\n",
       "        [0.84315654, 0.28832606],\n",
       "        [0.9376441 , 0.12461392],\n",
       "        [0.90075981, 0.19344728],\n",
       "        [0.9101313 , 0.17349953],\n",
       "        [0.88110824, 0.22510293]]),\n",
       " array([[0.85642188, 0.29291479],\n",
       "        [0.87077199, 0.2856362 ],\n",
       "        [0.85165318, 0.31041275],\n",
       "        [0.87505228, 0.27413696],\n",
       "        [0.85991254, 0.28420509],\n",
       "        [0.79619367, 0.42554069],\n",
       "        [0.86465696, 0.29143888],\n",
       "        [0.8507256 , 0.32244711],\n",
       "        [0.84994263, 0.33363963],\n",
       "        [0.81053654, 0.39052081],\n",
       "        [0.86976282, 0.28756337],\n",
       "        [0.87499508, 0.26881152],\n",
       "        [0.75718441, 0.4597284 ],\n",
       "        [0.8841971 , 0.27745025],\n",
       "        [0.86717263, 0.28999509],\n",
       "        [0.86634121, 0.30685975],\n",
       "        [0.84590182, 0.33311772]]),\n",
       " array([[0.88297449, 0.22257663],\n",
       "        [0.90693866, 0.17821606],\n",
       "        [0.88925692, 0.21147858],\n",
       "        [0.9139162 , 0.17087633],\n",
       "        [0.88528118, 0.2203535 ],\n",
       "        [0.84609702, 0.28801187],\n",
       "        [0.90546428, 0.18428063],\n",
       "        [0.90868581, 0.17965878],\n",
       "        [0.89416925, 0.20371639],\n",
       "        [0.88103601, 0.23367631],\n",
       "        [0.90159569, 0.19029576],\n",
       "        [0.90518107, 0.18262912],\n",
       "        [0.82552317, 0.3203352 ],\n",
       "        [0.93309418, 0.13831967],\n",
       "        [0.89741177, 0.20120149],\n",
       "        [0.90024546, 0.19376352],\n",
       "        [0.87857499, 0.23081783]]),\n",
       " array([[0.88418184, 0.21899793],\n",
       "        [0.90821235, 0.17382204],\n",
       "        [0.88811185, 0.21289328],\n",
       "        [0.91770433, 0.16162467],\n",
       "        [0.89200248, 0.20757439],\n",
       "        [0.86304889, 0.25334078],\n",
       "        [0.9070348 , 0.17977058],\n",
       "        [0.9154083 , 0.1637925 ],\n",
       "        [0.89790246, 0.19475076],\n",
       "        [0.89247022, 0.20460714],\n",
       "        [0.9013448 , 0.18832987],\n",
       "        [0.90440512, 0.18329113],\n",
       "        [0.84663197, 0.28145528],\n",
       "        [0.93704232, 0.12653893],\n",
       "        [0.90055519, 0.19397053],\n",
       "        [0.91449785, 0.16626243],\n",
       "        [0.88164645, 0.22474427]]),\n",
       " array([[0.88252951, 0.22432502],\n",
       "        [0.90392146, 0.18637028],\n",
       "        [0.88726927, 0.21542904],\n",
       "        [0.91289727, 0.1738747 ],\n",
       "        [0.88215729, 0.22582531],\n",
       "        [0.84281668, 0.29497558],\n",
       "        [0.9055961 , 0.18366981],\n",
       "        [0.90573852, 0.18773438],\n",
       "        [0.89279769, 0.20935797],\n",
       "        [0.87915393, 0.23517592],\n",
       "        [0.89993015, 0.1928515 ],\n",
       "        [0.9033648 , 0.18585032],\n",
       "        [0.82102051, 0.32550697],\n",
       "        [0.93159993, 0.14225396],\n",
       "        [0.89738455, 0.20151105],\n",
       "        [0.90220169, 0.19310272],\n",
       "        [0.88111533, 0.2285577 ]])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.performance for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(m, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_dict': OrderedDict([('layer_sga_emb.weight',\n",
       "               tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                       [-0.0015,  0.0031,  0.0028,  ...,  0.0031, -0.0041, -0.0042],\n",
       "                       [-0.0074,  0.0042, -0.0045,  ..., -0.0043,  0.0013, -0.0031],\n",
       "                       ...,\n",
       "                       [-0.0017,  0.0023,  0.0006,  ...,  0.0092, -0.0037,  0.0006],\n",
       "                       [-0.0011,  0.0025,  0.0034,  ..., -0.0087,  0.0001,  0.0044],\n",
       "                       [ 0.0004,  0.0001,  0.0026,  ...,  0.0100, -0.0037, -0.0024]])),\n",
       "              ('layer_can_emb.weight',\n",
       "               tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "                       [-0.1145,  0.0846, -0.0173,  ...,  0.0548,  0.1046,  0.0716],\n",
       "                       [ 0.1155, -0.0457, -0.0351,  ...,  0.0802, -0.0854, -0.1762],\n",
       "                       ...,\n",
       "                       [-0.0370, -0.0143, -0.0428,  ..., -0.0191, -0.0795, -0.0183],\n",
       "                       [ 0.0272, -0.1091,  0.0230,  ..., -0.1312, -0.0178,  0.0254],\n",
       "                       [-0.0262,  0.0012,  0.0481,  ...,  0.0265,  0.0169,  0.0447]])),\n",
       "              ('layer_w_0.weight',\n",
       "               tensor([[-6.5072e-18,  4.4378e-18,  2.9326e-18,  ..., -1.0024e-17,\n",
       "                        -1.4624e-19, -4.6771e-19],\n",
       "                       [ 2.8845e-16, -7.4660e-17,  1.4222e-16,  ...,  5.4678e-16,\n",
       "                         5.8687e-16,  1.6862e-16],\n",
       "                       [-1.7556e-18,  1.0380e-18,  1.1687e-18,  ..., -1.3478e-18,\n",
       "                         1.9924e-18,  3.6617e-19],\n",
       "                       ...,\n",
       "                       [-1.5883e-16,  8.0742e-18, -2.6474e-16,  ..., -5.1559e-16,\n",
       "                        -7.7248e-16, -1.7552e-16],\n",
       "                       [-7.5967e-08,  2.2540e-08, -6.3625e-08,  ..., -2.1491e-07,\n",
       "                        -1.6088e-07, -4.6761e-08],\n",
       "                       [ 6.2304e-17,  6.5267e-18, -5.8256e-17,  ..., -3.3576e-17,\n",
       "                        -5.9454e-17,  2.7251e-17]])),\n",
       "              ('layer_w_0.bias',\n",
       "               tensor([ 1.6013e-21, -2.2333e-20,  4.6160e-22,  3.2878e-17, -1.8802e-17,\n",
       "                        2.0312e-17,  1.0795e-14, -1.5694e-20, -2.7724e-04, -7.1852e-22,\n",
       "                        1.0514e-20,  5.6977e-18, -4.3455e-18, -1.9265e-11, -1.7048e-11,\n",
       "                        3.0286e-23, -5.2292e-18,  7.9258e-22,  2.3123e-18,  5.9346e-21,\n",
       "                       -3.3020e-20,  5.4669e-21, -2.7876e-18,  6.3383e-10, -2.1227e-22,\n",
       "                       -6.5080e-10,  5.1970e-13, -9.6388e-19,  1.4348e-18,  1.9301e-15,\n",
       "                       -3.1072e-20,  4.9342e-22,  1.0112e-11, -2.8768e-17, -1.9754e-17,\n",
       "                        1.3891e-01, -4.0769e-22,  6.1935e-21,  2.4311e-16, -3.6522e-22,\n",
       "                        7.1081e-13, -1.0557e-17, -8.9107e-23,  1.0602e-17, -2.2556e-19,\n",
       "                       -2.1169e-19,  2.4978e-21,  5.0643e-22,  8.7356e-12,  3.0661e-18,\n",
       "                        1.4581e-12,  6.7119e-13, -2.6028e-19, -1.0701e-19,  2.4562e-20,\n",
       "                       -1.5046e-11, -8.9364e-11,  1.2193e-20, -2.3169e-02,  7.6620e-20,\n",
       "                       -6.8754e-10,  4.4721e-22, -2.9449e-20,  1.2891e-22,  3.6361e-13,\n",
       "                        1.4587e-15, -9.2226e-18, -9.6153e-14,  9.6124e-03, -2.1022e-20,\n",
       "                        3.6510e-20, -1.0218e-21,  3.1976e-22,  1.5077e-11,  6.4637e-19,\n",
       "                        3.4993e-15, -8.9392e-13,  1.0456e-07, -7.8700e-12,  1.9429e-20,\n",
       "                        9.6114e-13, -9.9928e-16, -9.9744e-18, -5.3249e-19, -1.1709e-12,\n",
       "                        4.2296e-12, -2.0961e-20, -2.6528e-13, -2.1947e-13,  2.2216e-18,\n",
       "                       -1.7256e-15,  8.3688e-19, -1.0693e-10, -6.9548e-04,  3.4898e-13,\n",
       "                       -3.4114e-19,  1.1277e-19, -4.9806e-22,  7.5628e-19,  1.0634e-15,\n",
       "                       -1.4976e-19, -5.5016e-16,  3.2092e-13, -2.5155e-19,  6.0681e-22,\n",
       "                        6.7880e-21, -4.0419e-19, -1.2882e-21,  1.5737e-09,  5.3191e-20,\n",
       "                       -1.4770e-16,  2.3651e-18, -1.2030e-13,  1.1476e-16, -1.3050e-17,\n",
       "                       -2.2543e-11, -4.6253e-20,  3.4636e-16,  1.6174e-08,  4.8103e-17,\n",
       "                       -1.0049e-22,  1.0059e-11,  1.2616e-16, -5.6712e-20,  2.1481e-22,\n",
       "                       -9.2309e-19, -1.6119e-21, -2.7569e-02,  7.3135e-19, -1.0476e-14,\n",
       "                       -3.3675e-02, -3.6357e-11, -6.5232e-21,  2.5705e-15,  2.7040e-21,\n",
       "                        5.2405e-05,  1.9120e-08, -6.0537e-22, -4.3703e-20,  3.9373e-21,\n",
       "                        4.2739e-09,  2.7726e-20, -2.1215e-21,  3.9021e-05, -3.1478e-22,\n",
       "                        4.8699e-16, -1.4613e-18,  1.8189e-19,  3.2766e-02,  5.3491e-21,\n",
       "                       -7.8576e-19, -6.3022e-18,  1.6445e-19,  1.0004e-15, -7.1443e-15,\n",
       "                       -1.7651e-17, -1.8845e-21,  4.7200e-05, -2.7635e-12, -1.7143e-17,\n",
       "                       -2.9360e-10,  1.9397e-22,  5.6114e-09, -2.8953e-04, -2.7091e-21,\n",
       "                        3.7915e-22,  4.5786e-12,  4.1611e-21, -8.9292e-18,  2.6581e-18,\n",
       "                        9.1413e-22,  1.0538e-09, -5.8691e-13,  2.2607e-17,  1.1997e-12,\n",
       "                       -1.1998e-12,  2.9373e-20, -3.7253e-22,  9.9628e-19,  3.0509e-02,\n",
       "                       -5.7567e-09, -4.6989e-22, -5.2085e-09,  1.8098e-19, -1.9852e-20,\n",
       "                       -5.5455e-16, -2.7464e-18,  3.8803e-19,  2.3297e-07, -1.3304e-02,\n",
       "                        4.5638e-15, -1.6291e-16,  1.8959e-12,  1.4159e-16,  1.7081e-12,\n",
       "                        6.9504e-12, -2.0083e-13, -4.3456e-02,  1.6290e-22,  1.0822e-23,\n",
       "                       -2.5664e-16,  4.8622e-10, -4.3026e-13, -1.5389e-18, -8.9034e-19,\n",
       "                       -1.0458e-20,  1.4148e-01,  1.5572e-21,  7.8129e-15,  3.9272e-22,\n",
       "                       -1.1533e-06, -2.2638e-21,  3.1871e-22,  1.7579e-06,  4.9055e-14,\n",
       "                       -9.1103e-23,  6.3390e-13, -3.8586e-14,  3.6464e-16,  1.8739e-15,\n",
       "                       -8.2463e-21, -5.3399e-13, -3.4472e-22, -7.5700e-22,  2.4743e-22,\n",
       "                       -3.4735e-20, -2.7532e-02,  2.5629e-20, -2.8302e-16,  1.9145e-11,\n",
       "                       -4.3683e-20, -4.8387e-20, -6.3794e-22,  4.2269e-20,  3.1085e-21,\n",
       "                       -2.6750e-20, -4.6397e-20,  5.4873e-21, -1.3001e-14,  3.7350e-20,\n",
       "                        1.6067e-21,  6.1176e-10, -1.3127e-20,  1.2007e-09, -8.4836e-03,\n",
       "                       -1.9422e-20, -4.1050e-19,  3.1071e-22,  1.7175e-19,  3.1107e-13,\n",
       "                       -1.4041e-18, -1.8234e-22,  2.8040e-12, -3.1350e-20,  1.1564e-11,\n",
       "                       -7.6828e-21])),\n",
       "              ('layer_beta.weight',\n",
       "               tensor([[-3.2971e-18,  9.6755e-16,  3.1576e-18,  ..., -2.0685e-16,\n",
       "                        -2.8573e-08, -6.2904e-17],\n",
       "                       [-3.4191e-18,  9.5992e-16,  3.1203e-18,  ..., -2.1898e-16,\n",
       "                        -2.8756e-08, -5.5425e-17],\n",
       "                       [-3.5956e-18,  9.4417e-16,  3.0578e-18,  ..., -2.1535e-16,\n",
       "                        -2.8658e-08, -6.1535e-17],\n",
       "                       ...,\n",
       "                       [-3.4991e-18,  9.3726e-16,  3.0966e-18,  ..., -2.1381e-16,\n",
       "                        -2.8249e-08, -5.6863e-17],\n",
       "                       [-3.5551e-18,  9.7867e-16,  3.1061e-18,  ..., -2.0788e-16,\n",
       "                        -2.7123e-08, -5.6175e-17],\n",
       "                       [-3.4404e-18,  1.0073e-15,  3.1578e-18,  ..., -2.1394e-16,\n",
       "                        -2.8596e-08, -5.7069e-17]])),\n",
       "              ('layer_beta.bias',\n",
       "               tensor([ 4.8359e-05,  8.3412e-05,  8.7431e-05,  2.0082e-05, -6.2101e-05,\n",
       "                       -3.5952e-05, -1.2076e-05, -5.0487e-05,  1.0272e-04, -2.7631e-05,\n",
       "                       -4.3927e-05,  5.7001e-05, -1.5834e-05, -3.9575e-05, -8.2773e-06,\n",
       "                        2.1087e-05])),\n",
       "              ('layer_w_1.weight',\n",
       "               tensor([[-0.0426, -0.0290, -0.0417,  ..., -0.0445,  0.0071,  0.0244],\n",
       "                       [-0.0298, -0.0011,  0.0490,  ...,  0.0683,  0.0157, -0.0534],\n",
       "                       [-0.0155,  0.0172, -0.0202,  ...,  0.1862,  0.0375, -0.1046],\n",
       "                       ...,\n",
       "                       [ 0.0076,  0.0125,  0.0261,  ...,  0.0178,  0.0680,  0.0198],\n",
       "                       [-0.0348,  0.0926, -0.0574,  ...,  0.0157,  0.0563,  0.0566],\n",
       "                       [-0.0135, -0.0030, -0.0860,  ..., -0.0168, -0.1405, -0.0792]])),\n",
       "              ('layer_w_1.bias',\n",
       "               tensor([-0.0028, -0.0282, -0.0067, -0.0119, -0.0541,  0.0255,  0.0045, -0.0225,\n",
       "                        0.0171, -0.0109, -0.0263,  0.0051,  0.0239,  0.0116,  0.0113,  0.0046,\n",
       "                        0.0156, -0.0148, -0.0144, -0.0031,  0.0430,  0.0440, -0.0386, -0.0045,\n",
       "                        0.0188,  0.0321, -0.0008,  0.0113, -0.0135, -0.0379,  0.0109,  0.0163,\n",
       "                       -0.0313, -0.0633, -0.0364,  0.0559, -0.0060, -0.0087, -0.0014, -0.0026,\n",
       "                        0.0508,  0.0114,  0.0043,  0.0060, -0.0373,  0.0525,  0.0252, -0.0340,\n",
       "                        0.0361, -0.0009])),\n",
       "              ('bnorm_pathways.weight',\n",
       "               tensor([0.4048, 0.5253, 0.4589, 0.3835, 0.4908, 0.5665, 0.4372, 0.3901, 0.4252,\n",
       "                       0.3932, 0.5208, 0.3591, 0.4459, 0.4059, 0.4121, 0.4386, 0.4235, 0.3550,\n",
       "                       0.4859, 0.5239, 0.3522, 0.4088, 0.4769, 0.4335, 0.3842, 0.3610, 0.3756,\n",
       "                       0.4753, 0.4872, 0.4339, 0.4403, 0.4137, 0.4261, 0.4487, 0.5064, 0.3865,\n",
       "                       0.5280, 0.4619, 0.4410, 0.4682, 0.3910, 0.4250, 0.4922, 0.3746, 0.4159,\n",
       "                       0.4079, 0.5644, 0.5225, 0.4021, 0.4366])),\n",
       "              ('bnorm_pathways.bias',\n",
       "               tensor([ 0.1599, -0.1444, -0.1781, -0.0444, -0.2667,  0.0492, -0.2588,  0.0665,\n",
       "                       -0.0848, -0.1071, -0.2825,  0.1238, -0.0015,  0.0257, -0.0400,  0.0824,\n",
       "                       -0.1264,  0.0526, -0.0777, -0.0902, -0.0749, -0.0311, -0.0501,  0.1506,\n",
       "                        0.0205, -0.1789, -0.1470, -0.0041,  0.0445, -0.0852,  0.0430, -0.0332,\n",
       "                        0.1180, -0.3028, -0.2168,  0.0851, -0.0257,  0.0098, -0.1664,  0.1547,\n",
       "                        0.0436,  0.0408, -0.0735, -0.0288, -0.0183,  0.1907, -0.0827, -0.5831,\n",
       "                        0.1486,  0.1258])),\n",
       "              ('bnorm_pathways.running_mean',\n",
       "               tensor([ 0.0048, -0.0103,  0.0325, -0.0209, -0.0584,  0.0050,  0.0380, -0.0298,\n",
       "                        0.0357, -0.0710, -0.0010,  0.0048,  0.0317,  0.0099,  0.0171, -0.0150,\n",
       "                        0.0301,  0.0074, -0.0487, -0.0494,  0.0735,  0.0753, -0.0286,  0.0349,\n",
       "                        0.0321,  0.0465, -0.0029, -0.0113, -0.0574, -0.0184, -0.0241,  0.0328,\n",
       "                       -0.0242, -0.0408, -0.0471,  0.0413,  0.0042, -0.0112,  0.0187,  0.0404,\n",
       "                        0.0152,  0.0483,  0.0141, -0.0175,  0.0392,  0.0537,  0.0266, -0.0521,\n",
       "                        0.0254,  0.0232])),\n",
       "              ('bnorm_pathways.running_var',\n",
       "               tensor([0.1829, 0.2079, 0.1927, 0.1261, 0.2194, 0.2241, 0.1907, 0.1694, 0.1345,\n",
       "                       0.1667, 0.1768, 0.1276, 0.2190, 0.1322, 0.1623, 0.1373, 0.2120, 0.1862,\n",
       "                       0.2482, 0.2741, 0.1605, 0.2390, 0.1062, 0.1853, 0.2042, 0.1413, 0.1725,\n",
       "                       0.2554, 0.1577, 0.1419, 0.2195, 0.1007, 0.1143, 0.1189, 0.2095, 0.1506,\n",
       "                       0.1505, 0.1232, 0.1691, 0.1590, 0.1198, 0.1002, 0.1360, 0.1641, 0.2005,\n",
       "                       0.1260, 0.1408, 0.1115, 0.1262, 0.1223])),\n",
       "              ('bnorm_pathways.num_batches_tracked', tensor(1788)),\n",
       "              ('pathways.weight',\n",
       "               tensor([[ 0.0519,  0.0000, -0.0028,  ...,  0.0000,  0.0000, -0.0648],\n",
       "                       [ 0.0194, -0.0949, -0.0623,  ...,  0.0782,  0.1189, -0.0000],\n",
       "                       [-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "                       ...,\n",
       "                       [ 0.0000, -0.0000,  0.0000,  ..., -0.1927, -0.0000,  0.0000],\n",
       "                       [-0.0000,  0.1131, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
       "                       [ 0.0382,  0.0354,  0.0112,  ..., -0.0000,  0.0000,  0.0342]])),\n",
       "              ('pathways.bias',\n",
       "               tensor([-8.7417e-02,  4.5622e-02, -3.6034e-02, -3.1531e-02,  4.9733e-02,\n",
       "                        7.4824e-02, -2.2290e-05,  2.4329e-02,  1.6121e-06,  4.9026e-02,\n",
       "                        2.5068e-02,  1.2917e-02,  1.2525e-02, -7.5029e-02, -4.2465e-02,\n",
       "                       -3.7220e-02, -9.9507e-02, -8.1179e-02, -1.2016e-01, -7.0034e-03,\n",
       "                       -2.7183e-02,  4.2502e-03,  2.3422e-01,  1.4388e-02, -7.4570e-02,\n",
       "                       -1.4445e-01, -6.0074e-02, -1.6440e-02, -1.6340e-04,  8.0526e-02,\n",
       "                        2.7813e-02, -1.0729e-02, -4.7494e-02, -3.6754e-03, -7.0021e-03,\n",
       "                       -7.9275e-02,  2.3387e-02,  1.3534e-02, -1.0072e-01, -9.0188e-02,\n",
       "                        6.1718e-03, -1.8208e-02,  7.9110e-02,  1.6852e-02,  2.4130e-02,\n",
       "                        5.7316e-02, -1.7582e-02, -5.9558e-02, -7.9549e-02, -5.2102e-02,\n",
       "                       -5.7141e-02, -9.2602e-02, -9.1761e-03,  2.9122e-02, -3.0083e-03,\n",
       "                       -3.8886e-02, -9.9190e-02, -8.8773e-02,  2.8739e-02,  4.7092e-02,\n",
       "                       -3.3443e-03,  1.3664e-02, -4.3565e-02,  5.1241e-02, -2.9150e-02,\n",
       "                        2.3500e-02,  2.9012e-02, -1.6364e-02, -8.9140e-02, -4.9898e-02,\n",
       "                        4.2501e-02, -1.1887e-01, -9.9405e-02, -2.6847e-03,  2.6798e-02,\n",
       "                       -8.6475e-02, -4.8266e-02,  1.2171e-02, -1.9823e-02,  2.8561e-03,\n",
       "                        1.3066e-02,  3.0161e-02,  9.6396e-03, -1.0906e-01,  4.3123e-02,\n",
       "                       -9.2987e-02,  5.0802e-02,  1.9133e-02,  5.0679e-03, -1.2067e-01,\n",
       "                       -8.4009e-03,  1.0562e-01,  1.7080e-02, -1.7101e-01,  1.9015e-02,\n",
       "                       -7.2388e-02, -4.9606e-02, -6.6922e-02,  3.9734e-02,  3.9351e-02,\n",
       "                        2.6314e-02, -3.1077e-02,  4.4699e-02, -8.3418e-02,  1.5896e-02,\n",
       "                        1.3371e-01, -2.6881e-02, -2.9171e-02, -1.0651e-01,  4.0514e-02,\n",
       "                        2.7201e-04, -6.8211e-02,  5.7576e-03, -2.1975e-02, -2.0664e-02,\n",
       "                       -1.5105e-02, -4.2967e-02,  6.0621e-02,  1.4855e-01,  7.7389e-02,\n",
       "                        1.0020e-01, -6.6076e-02,  1.1377e-01,  4.7197e-02,  1.5043e-01,\n",
       "                        1.4682e-01,  9.9189e-03, -1.5564e-04, -7.2741e-02, -9.8436e-03,\n",
       "                        1.2158e-01,  6.3346e-03, -4.6526e-02,  3.6025e-02, -6.6398e-02,\n",
       "                       -7.7053e-02, -1.3629e-02, -1.0625e-02, -3.1350e-02,  9.1905e-03,\n",
       "                        6.3740e-03, -1.1312e-01,  1.1434e-02, -3.1773e-02,  2.3129e-02,\n",
       "                       -3.9320e-02, -3.1612e-02, -2.8937e-02,  5.9646e-02,  6.0664e-03,\n",
       "                       -2.2772e-02,  3.9171e-03,  3.4184e-02,  8.3493e-03, -1.8168e-03,\n",
       "                        1.6690e-03, -2.2443e-02,  1.3699e-01,  7.1488e-02, -2.3510e-02,\n",
       "                       -8.6664e-03, -2.9732e-02, -3.9727e-02, -1.6317e-02,  2.3225e-02,\n",
       "                        4.9087e-02,  2.0589e-02, -2.5818e-02, -5.1849e-04, -2.0793e-01,\n",
       "                        1.1119e-01, -1.1434e-02, -3.7020e-02, -5.4005e-02,  2.5479e-02,\n",
       "                        1.1670e-01,  1.1562e-05, -1.0657e-02,  8.3560e-03,  8.8577e-02,\n",
       "                       -6.1762e-03,  3.6686e-02,  1.4231e-01,  3.1467e-02, -6.9561e-02,\n",
       "                       -4.1113e-03, -2.1073e-03, -1.6127e-02,  4.3194e-04, -4.3318e-04,\n",
       "                        1.6557e-02, -6.3216e-03, -1.6591e-01,  1.9612e-04, -1.2174e-01,\n",
       "                       -9.6457e-03,  2.9497e-02,  5.3433e-02,  9.7919e-02, -5.0239e-02,\n",
       "                       -1.7087e-01,  2.9961e-02, -7.6395e-02,  4.9483e-02, -3.0078e-02,\n",
       "                       -3.0468e-02,  2.3999e-02, -2.8687e-02, -3.3181e-02,  1.3451e-02,\n",
       "                        1.9980e-02, -6.5873e-02, -9.3085e-02, -1.2629e-01, -2.9761e-02,\n",
       "                       -2.9576e-02, -1.8736e-01, -4.8815e-02, -2.1863e-02, -3.5353e-02,\n",
       "                       -8.3085e-02,  3.1672e-06, -1.1326e-01,  3.7720e-03, -8.8667e-03,\n",
       "                        5.8983e-02,  1.6941e-05,  1.2106e-01, -3.4983e-02,  1.3263e-04,\n",
       "                        1.6210e-02,  8.3137e-03,  4.1369e-02,  1.6268e-02, -5.0045e-03,\n",
       "                       -2.4799e-02, -1.2959e-02,  6.0735e-03, -1.3920e-01, -1.1495e-01,\n",
       "                        8.1471e-02, -2.2200e-02, -5.6217e-04, -6.5955e-02,  2.7109e-02,\n",
       "                       -5.0049e-02, -3.8982e-02,  1.1870e-02, -4.9580e-02, -3.7952e-02,\n",
       "                       -9.9678e-02, -1.4256e-06, -4.9740e-05,  6.5726e-05,  2.4872e-02,\n",
       "                       -3.2159e-02, -1.3182e-02, -1.4606e-04, -6.7380e-02, -6.6057e-03,\n",
       "                        5.5324e-02,  5.1344e-02, -2.4209e-02,  9.7643e-06,  5.8215e-02,\n",
       "                       -1.6836e-07,  2.4583e-02, -3.9417e-02,  2.6696e-02, -1.0669e-01,\n",
       "                        2.0554e-02, -1.1209e-04,  2.1906e-02,  2.3935e-03, -7.3563e-03,\n",
       "                        9.3000e-03,  3.2927e-02, -1.2084e-02, -3.0718e-02,  3.6876e-02,\n",
       "                       -2.2295e-03, -1.2679e-01,  1.3455e-01,  3.5320e-02,  1.8057e-02,\n",
       "                        3.2649e-02, -5.8331e-03, -1.5435e-01, -2.7668e-02, -4.2250e-02,\n",
       "                        1.0366e-02,  6.8531e-02,  1.0335e-01, -1.2214e-01, -3.5173e-02,\n",
       "                       -2.2770e-02,  1.0261e-01, -2.7839e-02,  1.3469e-01,  3.3104e-05,\n",
       "                        1.6364e-02, -9.4583e-02,  1.7223e-02, -3.6464e-02,  2.0949e-02,\n",
       "                        6.8405e-03, -1.1201e-01, -4.6357e-02,  1.2194e-01,  2.0766e-01,\n",
       "                        9.0605e-02, -2.8551e-03, -2.5803e-02, -8.7555e-03, -5.3810e-03,\n",
       "                       -6.7776e-02, -1.4078e-01, -9.5876e-02, -6.1073e-03,  1.7042e-02])),\n",
       "              ('bnorm_tf.weight',\n",
       "               tensor([ 8.1870e-01,  9.8438e-01,  5.2052e-01,  8.1214e-01,  5.4169e-01,\n",
       "                        1.0964e+00,  1.2946e-03,  6.0173e-01, -2.1058e-05,  5.3521e-01,\n",
       "                        8.7478e-01, -9.6792e-02,  6.8305e-01,  6.4341e-01,  9.7447e-01,\n",
       "                        4.1507e-01,  1.0711e+00,  1.1031e+00,  9.2053e-01,  1.1123e+00,\n",
       "                        6.3722e-01,  7.9028e-01,  8.4381e-01,  5.9170e-01,  8.9212e-01,\n",
       "                        8.7693e-01,  8.6155e-01,  9.3380e-01,  4.9058e-01,  7.8574e-01,\n",
       "                        5.8782e-01,  7.4390e-01,  8.8138e-01,  1.0452e+00,  8.0843e-01,\n",
       "                        1.0124e+00,  7.0423e-01,  5.2785e-01,  9.9671e-01,  1.0711e+00,\n",
       "                        7.9082e-01, -2.1611e-02,  1.0538e+00,  1.3070e-01,  7.5353e-01,\n",
       "                        8.3766e-01,  4.7222e-01,  1.0105e+00,  8.5088e-01,  1.1656e+00,\n",
       "                        9.4040e-01,  6.5992e-01, -2.9632e-02,  2.1635e-01,  6.1827e-01,\n",
       "                        6.0033e-01,  6.8866e-01,  9.9131e-01,  8.6017e-01,  9.6419e-01,\n",
       "                        5.9630e-01,  6.9979e-01,  9.2543e-01,  2.8501e-01,  7.3943e-01,\n",
       "                        9.6484e-01,  1.0199e+00,  5.4685e-01,  5.9153e-01,  6.4590e-01,\n",
       "                        1.1130e+00,  1.1582e+00,  8.6629e-01,  5.3159e-01,  7.8422e-01,\n",
       "                        8.8768e-01,  6.3626e-01,  8.8111e-01,  9.4457e-01,  1.0201e+00,\n",
       "                        6.6745e-01,  6.9348e-01,  2.3512e-01,  6.7319e-01,  9.4282e-01,\n",
       "                        7.0625e-01,  7.3796e-01,  7.9947e-01,  5.0796e-01,  9.1439e-01,\n",
       "                        7.5302e-01,  7.5618e-01,  9.2460e-01,  6.3922e-01,  6.0766e-01,\n",
       "                        8.6033e-01,  3.8102e-01,  8.2951e-01,  5.1537e-01,  8.0710e-01,\n",
       "                        4.7796e-01,  7.3841e-01,  4.7428e-01,  8.4651e-01,  5.4339e-01,\n",
       "                        8.8783e-01,  6.2310e-01,  1.2156e+00,  6.9766e-01,  8.0419e-01,\n",
       "                        5.0410e-02,  7.1585e-01,  6.4798e-01,  1.1607e+00,  8.1214e-01,\n",
       "                        1.9517e-01,  6.2668e-01,  6.8616e-01,  1.0556e+00,  7.2683e-01,\n",
       "                        8.5650e-01,  8.2780e-01,  5.3701e-01,  8.3825e-01,  8.1632e-01,\n",
       "                        7.5525e-01,  1.8477e-01,  2.1186e-03,  9.8810e-01,  5.6914e-01,\n",
       "                        8.0175e-01,  1.1590e+00,  9.0910e-01,  7.1229e-01,  1.0817e+00,\n",
       "                        1.1304e+00,  6.6647e-01,  1.1849e-02,  8.0926e-01,  8.0100e-01,\n",
       "                        7.4023e-01,  6.9819e-01,  7.3478e-01,  9.8743e-01,  6.7282e-01,\n",
       "                        9.3675e-01,  8.2051e-01,  4.9098e-01,  6.1715e-01,  5.4431e-01,\n",
       "                        5.0765e-01,  8.5295e-01,  1.2181e+00,  8.9603e-01,  9.0000e-01,\n",
       "                        6.3713e-01,  7.5452e-01,  9.4946e-01,  8.6297e-01,  5.9101e-01,\n",
       "                        9.4478e-01, -3.7163e-03,  7.6467e-01,  7.8294e-01,  7.2226e-01,\n",
       "                        7.2288e-01, -1.2841e-04,  6.3908e-01,  1.3541e-04,  9.3513e-01,\n",
       "                        7.6953e-01,  9.6803e-01,  7.4341e-01,  8.4641e-01,  4.7528e-01,\n",
       "                        6.0147e-01, -9.4652e-05,  3.5206e-01,  7.8417e-01,  9.1670e-01,\n",
       "                        8.9460e-01,  4.9392e-01,  1.0464e+00,  6.9471e-01,  1.1044e+00,\n",
       "                        7.2106e-01,  8.0649e-01,  7.8735e-01,  7.2224e-03,  1.0424e+00,\n",
       "                        8.3724e-01,  1.1513e+00,  8.1483e-01, -1.1456e-03,  8.4150e-01,\n",
       "                        4.8501e-01,  1.0981e+00,  7.0934e-01,  7.7256e-01,  8.6922e-01,\n",
       "                        8.5424e-01,  8.5552e-01,  9.7955e-01,  1.0920e+00,  9.4236e-01,\n",
       "                        5.3785e-01,  1.0301e+00,  7.8502e-01,  5.8888e-01,  2.3633e-02,\n",
       "                        1.0509e-01,  6.6692e-01,  9.5098e-01,  7.5709e-01,  7.2983e-01,\n",
       "                        3.0162e-01,  7.6459e-01,  5.2761e-01,  2.3166e-01,  1.2313e+00,\n",
       "                        7.0132e-01,  4.6954e-04,  9.5567e-01,  6.3425e-01,  9.9166e-01,\n",
       "                        9.7426e-01,  1.1543e-04,  6.7303e-01,  7.4350e-01,  3.5887e-01,\n",
       "                        1.6990e-01,  6.7081e-01,  1.0107e+00,  1.1113e+00,  5.9869e-01,\n",
       "                        1.2767e+00,  6.5879e-01,  7.1194e-01,  9.9602e-01,  1.0466e+00,\n",
       "                        9.7264e-01,  6.5766e-01,  9.8632e-01,  4.8424e-01,  5.1153e-01,\n",
       "                        8.5598e-01,  6.9732e-01,  4.0441e-02,  6.9730e-01,  6.0212e-01,\n",
       "                        1.0126e+00,  2.1534e-05,  6.8159e-06,  5.3078e-03,  6.7998e-01,\n",
       "                        8.0701e-01,  8.3976e-01,  2.0813e-01,  9.6762e-01,  3.9171e-01,\n",
       "                        2.2821e-01,  5.5239e-01,  2.7135e-01,  1.5712e-03,  8.3892e-01,\n",
       "                        1.1322e-06,  9.0817e-01,  1.1602e+00,  4.7326e-01,  9.8036e-01,\n",
       "                        8.4768e-01,  2.5688e-03,  6.3096e-01,  7.0509e-01,  6.1515e-01,\n",
       "                        4.2252e-01,  9.1440e-01,  6.3921e-01,  6.1050e-01,  9.5250e-01,\n",
       "                        3.1763e-01,  1.0007e+00,  9.0610e-01,  8.3275e-01,  7.9177e-01,\n",
       "                        6.0076e-01,  2.2983e-02,  8.9832e-01,  8.4104e-01,  5.7237e-01,\n",
       "                        6.0366e-01,  6.1516e-01,  1.1258e+00,  5.6749e-01,  6.2057e-01,\n",
       "                       -4.5798e-03,  7.3204e-01,  1.9334e-01,  9.0941e-01, -1.2170e-04,\n",
       "                        5.2884e-01,  8.7590e-01,  6.3488e-01,  7.8031e-01,  6.7165e-01,\n",
       "                        6.3193e-01,  6.2989e-01,  7.5517e-01,  9.1803e-01,  1.1632e+00,\n",
       "                        9.1512e-01,  4.5919e-01,  5.1317e-01,  5.0379e-01,  6.8843e-01,\n",
       "                        5.8677e-01,  8.4633e-01,  9.0061e-01,  6.6482e-01,  1.2781e-01])),\n",
       "              ('bnorm_tf.bias',\n",
       "               tensor([-1.8621e-01, -6.1696e-01,  3.8387e-01, -6.6947e-01,  1.0930e-01,\n",
       "                        4.2157e-01,  1.6907e+00,  1.4623e-01, -8.3311e-01,  7.4079e-01,\n",
       "                        1.4698e-01,  1.1697e+00, -1.6720e-01, -4.6355e-01, -1.6157e-01,\n",
       "                       -6.3542e-01,  5.9536e-01,  7.0640e-01,  3.1986e-01,  5.2991e-02,\n",
       "                       -1.0096e+00, -1.8381e-01,  1.5642e-01, -4.1713e-01,  8.3717e-01,\n",
       "                       -6.6135e-01, -6.0114e-01, -2.6798e-01, -5.1412e-01,  6.0313e-01,\n",
       "                       -4.5841e-01, -3.1144e-01, -1.9751e-01,  3.9364e-01, -3.9984e-01,\n",
       "                        1.2054e-01, -7.3872e-01,  3.0601e-01, -3.2289e-01, -7.0679e-01,\n",
       "                       -1.9178e-01,  1.4805e+00,  2.9457e-01,  1.5339e+00, -5.9858e-01,\n",
       "                        3.4200e-01, -1.2200e-02,  2.3213e-01, -7.5969e-01,  3.6057e-01,\n",
       "                        5.1663e-01, -7.5324e-02, -8.7143e-01,  1.6721e+00, -1.6634e-01,\n",
       "                        1.4901e-01, -4.3744e-01, -1.6121e-01,  3.6075e-02, -5.9257e-02,\n",
       "                       -1.9339e-01, -9.3009e-01, -2.4482e-01,  1.3026e+00, -2.2644e-01,\n",
       "                        5.0098e-01, -2.5835e-01, -5.3884e-01, -6.7338e-01, -7.8460e-01,\n",
       "                       -3.9911e-01,  5.1495e-01,  6.4455e-01, -2.5945e-01,  8.6193e-01,\n",
       "                       -4.9905e-01, -2.4636e-01,  3.5754e-01,  8.9874e-02,  4.6877e-01,\n",
       "                       -3.0751e-01, -3.2140e-01, -7.6768e-01, -5.0838e-01, -6.6790e-01,\n",
       "                        1.0403e-01, -3.5869e-01, -6.4485e-02, -6.6915e-01,  2.5387e-01,\n",
       "                       -4.1709e-02,  3.8322e-02, -1.7418e-01, -8.2525e-01, -6.6932e-03,\n",
       "                       -7.8669e-01, -1.3868e+00,  6.7147e-02, -4.9906e-02, -7.4535e-01,\n",
       "                        3.3677e-02,  1.5969e-02,  1.1081e+00,  1.8887e-01, -1.2538e-01,\n",
       "                        3.0885e-01,  6.4363e-01, -6.3755e-01, -1.3429e+00,  1.1536e-02,\n",
       "                        1.1316e+00, -6.4988e-01, -6.7580e-01,  2.6037e-01, -5.6097e-01,\n",
       "                        1.7670e+00, -8.5714e-01,  5.4993e-01,  2.2721e-01, -2.9526e-01,\n",
       "                       -6.9150e-02,  3.9881e-02,  6.5494e-01,  2.3530e-01,  4.4699e-01,\n",
       "                       -3.9551e-01,  1.0393e+00, -1.4629e+00, -4.5457e-01, -2.8967e-01,\n",
       "                        6.2275e-01,  5.0939e-01, -3.9447e-01,  1.3118e-01,  3.5989e-01,\n",
       "                        2.1649e-01,  2.3485e-01, -1.1493e+00, -1.7503e-01, -8.1688e-02,\n",
       "                       -2.8318e-01,  5.3281e-02, -6.7333e-01,  3.8668e-01,  1.0489e-01,\n",
       "                       -5.5256e-01,  4.4110e-01,  2.9008e-01,  1.0401e-01, -3.8977e-01,\n",
       "                        1.3808e-01, -6.1038e-01, -2.6771e-01,  6.4240e-01, -2.7422e-01,\n",
       "                        1.7927e-01, -7.7470e-01, -5.5177e-01, -3.5248e-01,  2.2105e-01,\n",
       "                       -6.6309e-01, -1.6425e+00,  2.3588e-01,  1.5680e-01,  6.4426e-01,\n",
       "                       -6.3337e-01, -6.3894e-01,  2.5421e-01,  1.2236e+00, -9.1320e-01,\n",
       "                        7.3642e-02,  2.0375e-01,  8.8785e-02,  2.2487e-01,  5.0509e-02,\n",
       "                        3.3076e-01, -1.1219e+00,  2.8754e-02, -7.0100e-01, -3.6295e-01,\n",
       "                        6.8109e-01, -2.7748e-01,  1.2595e-01, -3.0152e-01,  2.0687e-01,\n",
       "                       -1.7338e-01,  4.7355e-01,  3.0799e-01,  1.6746e+00, -1.6777e-01,\n",
       "                       -9.3685e-01, -5.1575e-01, -5.1184e-01,  1.6574e+00, -5.9760e-01,\n",
       "                        1.4408e-01, -4.7586e-01,  4.5411e-01,  2.9374e-01, -4.7110e-01,\n",
       "                       -9.8719e-01, -2.8437e-01,  4.8965e-01, -5.3086e-01, -8.0150e-01,\n",
       "                       -6.6118e-01, -8.8500e-01, -6.3391e-01,  6.0118e-02, -2.0839e-01,\n",
       "                        1.1502e+00,  2.9443e-01,  3.9083e-01, -4.0115e-01, -1.1454e+00,\n",
       "                       -5.0001e-01, -2.8723e-01,  1.7304e-01, -8.9413e-01,  3.0909e-01,\n",
       "                        8.8390e-02,  1.7317e+00, -4.2558e-01, -3.8826e-01, -5.7706e-01,\n",
       "                       -6.7139e-01, -1.2867e+00,  4.1405e-02, -8.0403e-01, -3.9057e-01,\n",
       "                        1.4212e+00,  2.3767e-01, -5.2073e-01, -7.7573e-02, -1.6967e-01,\n",
       "                        6.3930e-01, -1.3768e-01,  1.7682e-01,  3.5168e-01, -6.8601e-01,\n",
       "                        4.0632e-01,  3.2776e-01, -5.4211e-01, -1.3549e+00,  7.7881e-01,\n",
       "                       -7.9853e-01, -8.4279e-01, -1.4858e+00, -2.7735e-01,  1.0388e-01,\n",
       "                       -8.4425e-01,  1.2812e+00,  1.8564e+00, -1.8631e+00,  6.9956e-01,\n",
       "                       -3.5108e-01, -7.9792e-01, -8.9114e-01,  2.0843e-03,  4.4434e-01,\n",
       "                        1.2246e+00, -7.2643e-01, -9.0842e-01,  1.2258e+00, -4.7274e-01,\n",
       "                        1.3538e+00, -8.5049e-02,  5.7591e-01, -8.7821e-02,  3.9082e-01,\n",
       "                        3.3039e-01,  1.6945e+00, -3.6175e-03,  8.6700e-01, -1.8701e-01,\n",
       "                        1.7549e-03,  4.1191e-01,  3.8481e-01, -1.8334e-01, -2.0351e-01,\n",
       "                       -1.0684e+00, -6.3425e-01, -7.4864e-01, -2.1817e-01, -4.1242e-01,\n",
       "                       -2.4711e-02,  1.1504e+00, -6.6251e-01, -2.2305e-01, -1.1008e+00,\n",
       "                        9.1892e-03,  8.9336e-03,  1.6681e-01, -8.3855e-01, -7.7070e-01,\n",
       "                        9.8837e-01,  1.9566e-01, -1.3044e+00,  4.7187e-01,  1.4769e+00,\n",
       "                        4.4430e-01,  2.6948e-01,  5.8005e-01, -3.4021e-01,  3.2796e-01,\n",
       "                        2.0752e-01, -2.4150e-01, -1.0563e+00, -1.3887e-01,  3.1384e-01,\n",
       "                       -1.1680e+00,  1.8040e-02, -4.8894e-01, -2.6138e-02, -1.4533e+00,\n",
       "                       -4.2418e-01, -7.9663e-01, -3.0690e-01,  3.3274e-01,  1.4386e+00])),\n",
       "              ('bnorm_tf.running_mean',\n",
       "               tensor([-2.6882e-02, -5.9211e-02,  1.2054e-02, -6.6918e-02,  7.3299e-04,\n",
       "                        3.2970e-02, -1.9817e-05, -1.9802e-02,  1.3566e-06,  4.1474e-02,\n",
       "                        1.0087e-02, -9.1876e-04,  1.4085e-02, -3.1619e-02, -2.3221e-02,\n",
       "                       -1.2873e-02,  5.2648e-02,  6.9096e-02,  2.5315e-02, -7.8782e-04,\n",
       "                       -8.3322e-02, -1.0112e-02,  3.1790e-02, -3.4771e-02,  6.7246e-02,\n",
       "                       -8.6937e-02, -5.3906e-02, -1.8795e-02,  1.5453e-03,  4.9996e-02,\n",
       "                       -8.5935e-03, -6.6809e-03, -3.1920e-02,  5.7939e-02, -1.7699e-02,\n",
       "                        1.0545e-02, -1.5835e-02,  9.8181e-03, -3.7428e-02, -4.7819e-02,\n",
       "                       -8.6662e-03, -1.8884e-02,  3.6483e-02,  7.6469e-03, -1.1566e-02,\n",
       "                        5.3607e-02, -4.1370e-03,  1.0778e-02, -6.5077e-02,  5.9479e-02,\n",
       "                        1.9393e-02, -2.7260e-02, -8.2627e-03,  5.0406e-03, -7.4760e-03,\n",
       "                        1.4150e-02, -1.7519e-02, -2.1426e-02, -6.9463e-03,  1.4503e-02,\n",
       "                       -8.9348e-03, -4.1335e-02, -2.7428e-02,  2.0781e-02, -3.1503e-02,\n",
       "                        3.5790e-02,  5.0643e-03, -1.9052e-02, -6.1257e-02, -5.8255e-02,\n",
       "                       -5.5410e-02,  3.8779e-02,  3.3136e-02, -2.1319e-02,  1.0991e-01,\n",
       "                       -4.4504e-02, -1.3062e-02,  2.7041e-02, -5.2235e-03,  2.5553e-02,\n",
       "                       -1.1302e-02, -2.6667e-02, -7.2460e-03, -5.9477e-02, -7.6115e-02,\n",
       "                       -6.4560e-04, -3.7389e-03, -3.7734e-04, -3.5490e-02,  1.7771e-02,\n",
       "                       -2.7563e-04,  6.2082e-03, -1.3303e-02, -1.1027e-01,  1.2187e-02,\n",
       "                       -7.2925e-02, -3.8902e-02, -4.0511e-03,  8.3985e-03, -2.8782e-02,\n",
       "                       -3.0140e-03,  1.7472e-02,  3.9715e-02,  8.1352e-03, -6.4562e-03,\n",
       "                        4.9961e-02,  2.1809e-02, -3.5430e-02, -9.8757e-02,  1.2879e-03,\n",
       "                       -4.8212e-03, -2.3560e-02, -4.7305e-02,  8.6068e-03, -2.4766e-02,\n",
       "                       -1.1299e-02, -6.1526e-02,  2.8484e-02,  1.7321e-02, -1.6037e-02,\n",
       "                        3.8613e-03, -9.1671e-03,  2.7318e-02,  2.9893e-02,  8.4697e-02,\n",
       "                       -2.6910e-02,  1.5325e-02, -9.9922e-05, -3.4173e-02, -2.4756e-02,\n",
       "                        9.3249e-02,  1.7075e-02, -4.0054e-02,  1.2627e-02, -1.2404e-02,\n",
       "                        1.2553e-02,  8.0513e-03, -1.0493e-02, -2.4105e-02,  4.2005e-03,\n",
       "                       -1.1722e-02, -1.8781e-02, -4.0239e-02,  6.0837e-02,  6.2531e-03,\n",
       "                       -4.8490e-02,  2.6246e-02,  7.0780e-03,  6.7359e-03, -1.4240e-02,\n",
       "                       -2.6971e-03, -2.1663e-02, -1.7576e-02,  3.8242e-02, -2.6708e-03,\n",
       "                        3.1320e-03, -4.4832e-02, -2.4964e-02, -2.3482e-02,  7.8793e-03,\n",
       "                       -5.9210e-02, -3.0586e-02,  1.7181e-02,  5.5898e-04,  5.5786e-02,\n",
       "                       -3.6443e-02,  2.1724e-02,  4.5113e-04, -5.6316e-04, -8.4978e-02,\n",
       "                       -1.8613e-03,  2.2995e-02, -1.5164e-03, -3.5268e-03,  8.1309e-04,\n",
       "                        2.8769e-02,  1.3031e-05, -7.8886e-03, -4.4625e-02, -2.6256e-02,\n",
       "                        7.4141e-02, -9.5997e-03,  2.1970e-02, -4.8940e-03,  1.8721e-02,\n",
       "                       -3.9243e-03,  4.9889e-02, -1.0049e-03,  4.4357e-04,  8.3007e-03,\n",
       "                       -7.0937e-02, -5.2606e-02, -8.1619e-02,  2.0128e-04, -6.8831e-02,\n",
       "                       -4.0414e-03, -2.8121e-02,  2.3343e-02,  3.5257e-02, -2.8772e-02,\n",
       "                       -1.1581e-01, -4.7721e-02,  3.3115e-02, -4.3328e-02, -6.2565e-02,\n",
       "                       -1.0274e-02, -5.2052e-02, -7.9367e-02,  3.0965e-02,  1.3820e-02,\n",
       "                        6.1524e-03, -4.7498e-03,  2.6744e-02, -4.5395e-02, -8.1419e-02,\n",
       "                       -1.9850e-03, -3.6417e-02, -7.8825e-03, -7.8126e-03,  1.0415e-02,\n",
       "                       -1.5494e-02,  4.4602e-06, -4.5310e-02, -3.6666e-02, -3.7359e-02,\n",
       "                       -4.8372e-02,  2.1967e-05,  2.6227e-02, -4.0578e-02, -6.1409e-03,\n",
       "                        1.0386e-02,  1.7954e-02, -2.5956e-02, -6.1266e-03, -1.9386e-02,\n",
       "                        4.5777e-02, -4.2935e-03,  1.3032e-02,  3.5527e-02, -7.4870e-02,\n",
       "                        7.2806e-02,  1.0474e-02, -6.6281e-02, -7.8489e-02,  3.1779e-02,\n",
       "                       -7.0992e-02, -4.0756e-02,  4.4626e-03, -5.4015e-02,  1.8612e-02,\n",
       "                       -1.4103e-01, -9.9355e-07, -5.1965e-05,  8.5827e-05,  5.3029e-02,\n",
       "                       -4.0302e-02, -5.9833e-02, -6.5454e-03,  1.7941e-02,  4.3968e-03,\n",
       "                        3.6316e-02, -1.9398e-02, -3.2493e-03,  1.0046e-04, -3.5884e-02,\n",
       "                       -2.3350e-07, -3.3168e-02,  6.2692e-02, -5.0134e-05,  6.6021e-03,\n",
       "                        2.9564e-02, -9.7994e-05,  3.3154e-04,  4.1867e-02, -1.4228e-02,\n",
       "                        2.4895e-04,  7.5780e-02,  5.5533e-03, -1.5609e-02, -1.4194e-02,\n",
       "                       -2.5559e-02, -1.0299e-01, -3.7993e-02, -3.5674e-02, -2.8379e-02,\n",
       "                        4.0568e-03, -5.2338e-03, -5.0129e-02, -1.1253e-02, -8.0659e-02,\n",
       "                       -1.7324e-02,  2.2188e-03,  2.9023e-02, -8.1630e-02, -4.0677e-02,\n",
       "                       -2.3183e-02,  4.3885e-02,  3.5462e-03,  5.0396e-02,  3.2295e-05,\n",
       "                        2.0120e-02,  3.9239e-03,  1.1539e-02, -2.3271e-02,  2.1071e-02,\n",
       "                        7.1847e-03, -3.6815e-02, -7.6321e-02,  2.3920e-02,  7.9839e-02,\n",
       "                       -5.9253e-02,  9.5455e-03, -2.5622e-02, -9.5458e-03, -8.1934e-02,\n",
       "                       -2.7047e-02, -6.5574e-02, -2.6497e-02,  7.4872e-03,  7.0185e-03])),\n",
       "              ('bnorm_tf.running_var',\n",
       "               tensor([1.3769e-01, 2.5474e-01, 1.8478e-02, 1.1007e-01, 3.7342e-02, 5.8798e-02,\n",
       "                       4.4452e-10, 4.6746e-02, 3.3360e-12, 2.9333e-02, 6.3049e-02, 1.3365e-03,\n",
       "                       3.4599e-02, 1.0426e-01, 5.6735e-02, 7.4690e-03, 2.6959e-01, 2.5881e-01,\n",
       "                       1.6942e-01, 9.9446e-02, 1.2999e-01, 1.9843e-02, 1.3366e-01, 4.2337e-02,\n",
       "                       2.1611e-01, 1.1227e-01, 8.9960e-02, 4.5873e-02, 1.2763e-02, 4.0351e-02,\n",
       "                       4.8585e-02, 4.5894e-02, 4.9206e-02, 2.5033e-01, 6.2761e-02, 1.4362e-01,\n",
       "                       2.2127e-02, 2.2705e-02, 1.0284e-01, 5.1063e-02, 2.9974e-02, 3.3386e-04,\n",
       "                       1.8064e-01, 9.6788e-03, 3.7924e-02, 3.4451e-01, 1.0066e-02, 2.0893e-01,\n",
       "                       1.5443e-01, 2.8133e-01, 6.8098e-02, 4.2093e-02, 6.8797e-05, 3.5442e-02,\n",
       "                       2.0922e-02, 1.7286e-02, 6.4736e-02, 8.3553e-02, 2.7602e-01, 6.6181e-02,\n",
       "                       2.0548e-02, 8.0215e-02, 8.7175e-02, 1.7457e-02, 1.1043e-01, 1.3564e-01,\n",
       "                       3.0304e-02, 2.3300e-02, 1.1071e-01, 6.4486e-02, 2.2242e-01, 1.2254e-01,\n",
       "                       8.0510e-02, 5.4007e-02, 2.3498e-01, 1.3613e-01, 1.8595e-02, 8.2941e-02,\n",
       "                       4.6553e-02, 3.4220e-02, 2.1200e-01, 5.1468e-02, 4.4613e-03, 1.4904e-01,\n",
       "                       2.8091e-01, 4.4363e-02, 2.0183e-02, 3.6840e-02, 2.7719e-02, 2.5399e-01,\n",
       "                       7.7664e-02, 1.8478e-01, 1.9363e-01, 1.8830e-01, 1.4813e-02, 9.3165e-02,\n",
       "                       2.9264e-02, 7.6709e-02, 1.9885e-02, 2.3588e-02, 2.2878e-02, 3.8016e-02,\n",
       "                       3.4663e-02, 5.9853e-02, 2.9814e-02, 1.7062e-01, 5.4605e-02, 9.0847e-02,\n",
       "                       7.6437e-02, 2.6918e-02, 1.0077e-03, 6.7995e-02, 8.7364e-02, 9.8107e-02,\n",
       "                       5.3090e-02, 2.2558e-02, 1.1975e-01, 5.3066e-02, 4.0908e-01, 3.9813e-02,\n",
       "                       5.1871e-02, 1.3243e-01, 6.7770e-02, 1.2058e-01, 2.5814e-01, 5.6079e-02,\n",
       "                       6.5518e-03, 1.2630e-08, 1.5935e-01, 1.9506e-02, 2.9143e-01, 3.9488e-02,\n",
       "                       9.1100e-02, 1.1045e-01, 9.7696e-02, 1.0488e-01, 1.2670e-02, 1.1322e-04,\n",
       "                       4.8391e-02, 5.4256e-02, 2.4184e-02, 6.4569e-02, 4.7166e-02, 1.6997e-01,\n",
       "                       5.2209e-02, 1.7828e-01, 1.0031e-01, 1.1811e-02, 3.5003e-02, 1.6925e-02,\n",
       "                       1.1146e-02, 2.4400e-02, 1.8066e-01, 3.8713e-02, 8.5313e-02, 1.2956e-02,\n",
       "                       9.2573e-02, 1.3823e-01, 4.1291e-02, 1.1948e-02, 9.6518e-02, 8.8932e-04,\n",
       "                       6.1036e-02, 2.9137e-02, 8.2167e-02, 8.2529e-02, 4.2461e-04, 2.5055e-02,\n",
       "                       3.4960e-07, 8.3959e-02, 7.0963e-02, 1.7345e-01, 1.9107e-02, 4.3399e-02,\n",
       "                       1.4097e-02, 5.9372e-02, 1.6289e-10, 7.9211e-03, 1.2571e-01, 8.5204e-02,\n",
       "                       1.7646e-01, 8.7272e-03, 1.3772e-01, 1.8514e-02, 1.5887e-01, 4.1058e-02,\n",
       "                       1.8435e-01, 2.9575e-02, 1.7528e-07, 1.4384e-01, 9.3609e-02, 8.2090e-02,\n",
       "                       3.3187e-01, 3.9556e-08, 1.2731e-01, 1.0264e-02, 9.5844e-02, 5.6613e-02,\n",
       "                       2.5067e-01, 1.4491e-01, 1.2570e-01, 1.0756e-01, 1.0802e-01, 1.0324e-01,\n",
       "                       9.3055e-02, 1.5807e-02, 1.8135e-01, 2.6587e-01, 5.8750e-02, 1.8185e-04,\n",
       "                       3.2902e-03, 3.6940e-02, 1.1683e-01, 5.4323e-02, 9.9643e-02, 3.3707e-03,\n",
       "                       1.2307e-01, 1.4034e-02, 1.0940e-02, 7.6198e-02, 6.0642e-02, 1.1588e-10,\n",
       "                       6.2550e-02, 6.8202e-02, 6.0082e-02, 2.1508e-01, 5.1328e-10, 3.7384e-02,\n",
       "                       1.5651e-01, 3.7758e-03, 1.7716e-02, 3.9320e-02, 6.7632e-02, 9.8584e-02,\n",
       "                       4.1384e-02, 1.1347e-01, 2.6254e-02, 2.6901e-02, 1.2471e-01, 1.1603e-01,\n",
       "                       2.6873e-01, 2.0931e-02, 1.6932e-01, 5.1715e-02, 2.8467e-02, 7.9265e-02,\n",
       "                       4.3789e-02, 1.2415e-03, 1.0160e-01, 2.2434e-02, 2.8669e-01, 1.1586e-12,\n",
       "                       2.8967e-09, 7.5224e-09, 1.9027e-01, 1.0363e-01, 1.7410e-01, 7.7272e-03,\n",
       "                       6.8719e-02, 1.7383e-02, 3.5926e-02, 6.6001e-03, 7.7137e-02, 3.9563e-08,\n",
       "                       1.7354e-01, 5.7843e-14, 1.1693e-01, 1.6352e-01, 1.5323e-02, 9.7543e-02,\n",
       "                       1.6573e-01, 8.9462e-09, 1.9503e-02, 6.5206e-02, 4.0152e-02, 1.1583e-02,\n",
       "                       1.4542e-01, 4.4824e-02, 2.2796e-02, 5.1251e-02, 9.7900e-03, 1.6039e-01,\n",
       "                       1.2630e-01, 1.4503e-01, 4.1327e-02, 5.2962e-02, 2.8043e-05, 8.9071e-02,\n",
       "                       9.8050e-02, 5.6487e-02, 2.6127e-02, 9.1064e-02, 4.4423e-01, 8.6692e-02,\n",
       "                       3.2282e-02, 5.2312e-04, 1.2318e-01, 9.3273e-03, 1.3476e-01, 1.1593e-09,\n",
       "                       3.8425e-02, 4.4768e-02, 5.6938e-02, 4.8425e-02, 4.2742e-02, 1.7727e-02,\n",
       "                       1.1458e-01, 5.2632e-02, 2.4901e-01, 3.0207e-01, 1.1372e-01, 1.9575e-02,\n",
       "                       4.2671e-02, 1.8088e-02, 5.0973e-02, 3.9146e-02, 1.3634e-01, 6.7744e-02,\n",
       "                       7.3405e-02, 8.9783e-03])),\n",
       "              ('bnorm_tf.num_batches_tracked', tensor(1788)),\n",
       "              ('layer_w_2.weight',\n",
       "               tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.6131, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       ...,\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0023, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                       [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])),\n",
       "              ('layer_w_2.bias',\n",
       "               tensor([-0.1195,  0.0998, -1.1259,  ...,  0.9980,  0.2311,  0.5431]))]),\n",
       " 'performance': array([[0.87478431, 0.23440987],\n",
       "        [0.90336676, 0.18203429],\n",
       "        [0.88489022, 0.21772876],\n",
       "        [0.91863095, 0.15967136],\n",
       "        [0.90305224, 0.18760877],\n",
       "        [0.87848064, 0.2288077 ],\n",
       "        [0.90757834, 0.17763831],\n",
       "        [0.92331992, 0.15111389],\n",
       "        [0.89902934, 0.19403118],\n",
       "        [0.89161881, 0.20823204],\n",
       "        [0.90084218, 0.18905767],\n",
       "        [0.90289984, 0.18446447],\n",
       "        [0.85901448, 0.26625134],\n",
       "        [0.93919665, 0.1217536 ],\n",
       "        [0.89899881, 0.19596479],\n",
       "        [0.9159086 , 0.16278735],\n",
       "        [0.88269647, 0.22335659]]),\n",
       " 'pval_corr': 0.31012293543249553,\n",
       " 'cancers': ['BLCA',\n",
       "  'BRCA',\n",
       "  'CESC',\n",
       "  'COAD',\n",
       "  'ESCA',\n",
       "  'GBM',\n",
       "  'HNSC',\n",
       "  'KIRC',\n",
       "  'KIRP',\n",
       "  'LIHC',\n",
       "  'LUAD',\n",
       "  'LUSC',\n",
       "  'PCPG',\n",
       "  'PRAD',\n",
       "  'STAD',\n",
       "  'THCA',\n",
       "  'UCEC'],\n",
       " 'idd': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerConductance, LayerActivation, LayerIntegratedGradients\n",
    "from captum.attr import IntegratedGradients\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = pd.read_parquet('wt.parquet')\n",
    "sm_mut = pd.read_parquet('sm_mut.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f45dc03b604d0ba69540966ff80691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R = None\n",
    "S = None\n",
    "\n",
    "for model in tqdm(models):\n",
    "    model.eval()\n",
    "\n",
    "    X = torch.from_numpy(model.sga)[model.idx]\n",
    "    C = torch.from_numpy(model.can[model.idx])\n",
    "    r = model(X, C, pathways=True).data.numpy()\n",
    "\n",
    "    if R is None:\n",
    "        R = r\n",
    "    else:\n",
    "        R += r\n",
    "\n",
    "    X = torch.from_numpy(model.sga)[model.idy]\n",
    "    C = torch.from_numpy(model.can[model.idy])\n",
    "    s = model(X, C, pathways=True).data.numpy()\n",
    "\n",
    "    if S is None:\n",
    "        S = s\n",
    "    else:\n",
    "        S += s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((351, 50), (198, 50))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape, S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = R / len(models)\n",
    "S = S / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_predicted = pd.DataFrame(ttest_ind(R, S).pvalue, \n",
    "        index=hallmark.Description, \n",
    "        columns=['pvalue']).sort_values(by='pvalue', ascending=True).loc[hallmark.Description].pvalue.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_exp = hallmark['pvalue'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('p_predicted.npy', p_predicted)\n",
    "np.save('p_exp.npy', p_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(-np.log(p_predicted), -np.log(p_exp))\n",
    "plt.title(f'spearmanr: {spearmanr(p_predicted, p_exp).correlation:.5f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31012293543249553]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.pval_corr for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = model\n",
    "# M.analysis_mode = True\n",
    "# lc = LayerConductance(M, M.pathways)\n",
    "\n",
    "# results = []\n",
    "# AA = []\n",
    "\n",
    "# for frame, name in zip([wt, sm_mut, scna_mut, sm_scna_mut], ['WT', 'SM', 'SCNA', 'SM_SCNA']):\n",
    "#     if len(frame) == 0:\n",
    "#         break\n",
    "#     scores = []\n",
    "\n",
    "#     idx = xdf[xdf.id.isin(frame.index)].idx.values\n",
    "#     X = torch.from_numpy(dataset['sga'])\n",
    "\n",
    "#     # G = [i for i in data.gene_tf_sga.index if 'AKT' in i] + [i for i in data.gene_tf_sga.index if 'PIK' in i]\n",
    "#     # G = ['PIK3CA']\n",
    "#     # G = [i for i in data.gene_tf_sga.index if 'AKT' in i]\n",
    "#     # G = [i for i in data.gene_tf_sga.index if 'PIK' in i]\n",
    "    \n",
    "#     # G = ['AKT1', 'PIK3CA', 'AKT2']\n",
    "    \n",
    "#     G = ['NFE2L2']\n",
    "    \n",
    "#     # G = merged2['PI3K/AKT Signaling in Cancer']\n",
    "    \n",
    "#     # G = ['AKT1']\n",
    "\n",
    "#     for ix in tqdm([list(data.gep_sga.columns).index(g) for g in G if g in data.gep_sga.columns]):\n",
    "#         a = lc.attribute((X[idx], torch.from_numpy(dataset['can'][idx])), n_steps=5, \n",
    "#                         attribute_to_layer_input=True, target=[ix]*len(X[idx]))\n",
    "#         ig_attr_test_sum = a.detach().cpu().numpy().sum(0)\n",
    "#         ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)\n",
    "#         scores.append(ig_attr_test_norm_sum)\n",
    "        \n",
    "#     AA.append(a)\n",
    "#     g = np.array(_pathways[2])\n",
    "#     at = np.sum(scores, 0)\n",
    "\n",
    "#     assert g.shape == at.shape\n",
    "\n",
    "#     df = pd.DataFrame([g, at]).T\n",
    "#     df.columns = ['Pathways', f'score_{name}']\n",
    "#     results.append(df.set_index('Pathways'))\n",
    "    \n",
    "# AA = np.array([i.detach().numpy() for i in AA])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ca4c60b9725142802a45bac1edd24b8f9bd942fe20cefa4620c7c67c6b30065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
